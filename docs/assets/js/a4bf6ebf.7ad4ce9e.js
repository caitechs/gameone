"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8181],{3905:(e,n,t)=>{t.d(n,{Zo:()=>s,kt:()=>k});var o=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var d=o.createContext({}),c=function(e){var n=o.useContext(d),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},s=function(e){var n=c(e.components);return o.createElement(d.Provider,{value:n},e.children)},u="mdxType",p={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},m=o.forwardRef((function(e,n){var t=e.components,a=e.mdxType,r=e.originalType,d=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),u=c(t),m=a,k=u["".concat(d,".").concat(m)]||u[m]||p[m]||r;return t?o.createElement(k,i(i({ref:n},s),{},{components:t})):o.createElement(k,i({ref:n},s))}));function k(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var r=t.length,i=new Array(r);i[0]=m;var l={};for(var d in n)hasOwnProperty.call(n,d)&&(l[d]=n[d]);l.originalType=e,l[u]="string"==typeof e?e:a,i[1]=l;for(var c=2;c<r;c++)i[c]=t[c];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}m.displayName="MDXCreateElement"},4146:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>i,default:()=>p,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var o=t(83117),a=(t(67294),t(3905));const r={title:"\u5b89\u88c5",sidebar_position:1},i=void 0,l={unversionedId:"faq/setup",id:"faq/setup",title:"\u5b89\u88c5",description:"If you encounter problems during installation, such as cloudcore/edgecore don't start successfully, or they both start but edge nodes are always in NotReady, or pod cannot be deployed to edge nodes. This doc can help you debug how to fix the issues.",source:"@site/i18n/zh/docusaurus-plugin-content-docs/current/faq/setup.md",sourceDirName:"faq",slug:"/faq/setup",permalink:"/gameone/docs/faq/setup",draft:!1,editUrl:"https://github.com/kubeedge/website/blob/master/docs/faq/setup.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"\u5b89\u88c5",sidebar_position:1},sidebar:"documentationSideBar",previous:{title:"Frequently Asked Questions (FAQ)",permalink:"/gameone/docs/category/frequently-asked-questions-faq"}},d={},c=[{value:"How to check logs?",id:"how-to-check-logs",level:2},{value:"How to check cloudcore logs?",id:"how-to-check-cloudcore-logs",level:3},{value:"cloudcore in container mode",id:"cloudcore-in-container-mode",level:4},{value:"cloudcore in binary mode",id:"cloudcore-in-binary-mode",level:4},{value:"How to check edgecore logs?",id:"how-to-check-edgecore-logs",level:3},{value:"How to update configuration?",id:"how-to-update-configuration",level:2},{value:"How to modify cloudcore configuration?",id:"how-to-modify-cloudcore-configuration",level:3},{value:"cloudcore in container mode",id:"cloudcore-in-container-mode-1",level:4},{value:"cloudcore in binary mode",id:"cloudcore-in-binary-mode-1",level:4},{value:"How to modify edgecore configuration?",id:"how-to-modify-edgecore-configuration",level:3},{value:"cloudcore pre-flight check failed",id:"cloudcore-pre-flight-check-failed",level:2},{value:"timed out waiting for the condition",id:"timed-out-waiting-for-the-condition",level:2},{value:"cloudcore in pending status",id:"cloudcore-in-pending-status",level:3},{value:"cloudcore in ImagePullBackOff status",id:"cloudcore-in-imagepullbackoff-status",level:3},{value:"cloudcore in CrashLoopBackOff status",id:"cloudcore-in-crashloopbackoff-status",level:3},{value:"EdgeCore failed to get CA certificate",id:"edgecore-failed-to-get-ca-certificate",level:2},{value:"<code>keadm join</code> pull image failed in edge nodes",id:"keadm-join-pull-image-failed-in-edge-nodes",level:2},{value:"Token related issues",id:"token-related-issues",level:2},{value:"Error: token credentials are in the wrong format",id:"error-token-credentials-are-in-the-wrong-format",level:3},{value:"Invalid Token",id:"invalid-token",level:3},{value:"edgecore failed to pass the certificate verification",id:"edgecore-failed-to-pass-the-certificate-verification",level:2},{value:"Advertise-address related issues",id:"advertise-address-related-issues",level:2},{value:"Runtime(\u8fd0\u884c\u65f6)\u76f8\u5173\u95ee\u9898",id:"runtime\u8fd0\u884c\u65f6\u76f8\u5173\u95ee\u9898",level:2},{value:"unknown service runtime.v1alpha2.ImageService",id:"unknown-service-runtimev1alpha2imageservice",level:3},{value:"failed to reserve sandbox name",id:"failed-to-reserve-sandbox-name",level:3},{value:"cni plugin not initialized/cni config uninitialized",id:"cni-plugin-not-initializedcni-config-uninitialized",level:3},{value:"cgroup driver \u4e0d\u5339\u914d",id:"cgroup-driver-\u4e0d\u5339\u914d",level:3}],s={toc:c},u="wrapper";function p(e){let{components:n,...t}=e;return(0,a.kt)(u,(0,o.Z)({},s,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"If you encounter problems during installation, such as cloudcore/edgecore don't start successfully, or they both start but edge nodes are always in ",(0,a.kt)("inlineCode",{parentName:"p"},"NotReady"),", or pod cannot be deployed to edge nodes. This doc can help you debug how to fix the issues."),(0,a.kt)("h1",{id:"common-knowledge"},"Common knowledge"),(0,a.kt)("h2",{id:"how-to-check-logs"},"How to check logs?"),(0,a.kt)("p",null,"The first step to start investigating installation failures or when a thing does not work as expected, is to find and look at the related installation logs."),(0,a.kt)("h3",{id:"how-to-check-cloudcore-logs"},"How to check cloudcore logs?"),(0,a.kt)("h4",{id:"cloudcore-in-container-mode"},"cloudcore in container mode"),(0,a.kt)("p",null,"If you deploy ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," in container mode, in other words, when ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," is deployed inside a k8s cluster and managed by k8s directly, you can use ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl logs")," command to get cloudcore logs, just like below. First use ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl get pod -n kubeedge")," to get ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," pod NAME, and then run ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl logs cloudcore-f88bbf5bb-kcvf4 -n kubeedge"),"(please replace ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore-f88bbf5bb-kcvf4")," with the actual cloudcore pod name), and then you can get logs"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"# kubectl get pod -n kubeedge\nNAME                        READY   STATUS    RESTARTS   AGE\ncloudcore-f88bbf5bb-kcvf4   1/1     Running   0          50m\n# kubectl logs cloudcore-f88bbf5bb-kcvf4 -n kubeedge\nW1118 02:16:02.810219       1 validation.go:154] TLSTunnelPrivateKeyFile does not exist in /etc/kubeedge/certs/server.key, will load from secret\nW1118 02:16:02.810256       1 validation.go:157] TLSTunnelCertFile does not exist in /etc/kubeedge/certs/server.crt, will load from secret\nW1118 02:16:02.810263       1 validation.go:160] TLSTunnelCAFile does not exist in /etc/kubeedge/ca/rootCA.crt, will load from secret\nI1118 02:16:02.810280       1 server.go:92] Version: v1.12.0\n...\n...\n")),(0,a.kt)("h4",{id:"cloudcore-in-binary-mode"},"cloudcore in binary mode"),(0,a.kt)("p",null,"If you deploy ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," in binary mode, in other words, ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," is running as a service/process on the physical machine directly, you should check whether ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," is managed by ",(0,a.kt)("inlineCode",{parentName:"p"},"systemd")," or not. If so, you can run ",(0,a.kt)("inlineCode",{parentName:"p"},"journalctl -u cloudcore.service -xe")," to get cloudcore logs. If not, the cloudcore logs are written to file ",(0,a.kt)("inlineCode",{parentName:"p"},"/var/log/kubeedge/cloudcore.log"),", you can run ",(0,a.kt)("inlineCode",{parentName:"p"},"tail")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"cat")," related commands to read log file."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"# journalctl -u cloudcore.service -xe\n# tail -f /var/log/kubeedge/cloudcore.log\n# cat /var/log/kubeedge/cloudcore.log\n")),(0,a.kt)("h3",{id:"how-to-check-edgecore-logs"},"How to check edgecore logs?"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"edgecore")," is always installed in binary mode, that means ",(0,a.kt)("inlineCode",{parentName:"p"},"edgecore")," cannot be deployed to a container, it can only run as a physical progress on a machine. You should check whether ",(0,a.kt)("inlineCode",{parentName:"p"},"edgecore")," is managed by ",(0,a.kt)("inlineCode",{parentName:"p"},"systemd")," or not. If so, you should run ",(0,a.kt)("inlineCode",{parentName:"p"},"journalctl -u edgecore.service -xe"),". Or, the edgecore logs are written to file ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/kubeedge/kubeedge/edge/edgecore.log"),", you can run ",(0,a.kt)("inlineCode",{parentName:"p"},"tail")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"cat")," related commands to read log file."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"# journalctl -u edgecore.service -xe\n# tail -f /etc/kubeedge/kubeedge/edge/edgecore.log\n# cat /etc/kubeedge/kubeedge/edge/edgecore.log\n")),(0,a.kt)("h2",{id:"how-to-update-configuration"},"How to update configuration?"),(0,a.kt)("h3",{id:"how-to-modify-cloudcore-configuration"},"How to modify cloudcore configuration?"),(0,a.kt)("h4",{id:"cloudcore-in-container-mode-1"},"cloudcore in container mode"),(0,a.kt)("p",null,"If you deploy ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," in container mode, the cloudcore configuration file is stored in the ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," configmap of the ",(0,a.kt)("inlineCode",{parentName:"p"},"kubeedge")," namespace, and is automatically mounted to the ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," pod. You can get it using command ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl get configmap cloudcore -nkubeedge -oyaml"),". Cloudcore configuration is stored in its data field."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'# kubectl get configmap cloudcore -nkubeedge -oyaml\napiVersion: v1\ndata:\n  cloudcore.yaml: "apiVersion: cloudcore.config.kubeedge.io/v1alpha2\\nkind: CloudCore\\nkubeAPIConfig:\\n\n    \\ kubeConfig: \\"\\"\\n  master: \\"\\"\\nmodules:\\n  cloudHub:\\n    advertiseAddress:\\n\n    ...\n    ...\n')),(0,a.kt)("p",null,"If you want to update the cloudcore configuration, you can run ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl edit configmap cloudcore -n kubeedge")," to update it. After modifying the configmap data, you can find that the configuration file mapped in the pod to ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/kubeedge/config/cloudcore.yaml")," is updated the same as you would expect by exec to the cloudcore pod (using ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl exec")," command)."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'# kubectl get pod -nkubeedge\nNAME                        READY   STATUS    RESTARTS   AGE\ncloudcore-f88bbf5bb-kcvf4   1/1     Running   0          3m29s\n# kubectl exec -it cloudcore-f88bbf5bb-kcvf4 -nkubeedge sh\nkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.\n/ # cat /etc/kubeedge/config/cloudcore.yaml \napiVersion: cloudcore.config.kubeedge.io/v1alpha2\nkind: CloudCore\nkubeAPIConfig:\n  kubeConfig: ""\n  master: ""\nmodules:\n  cloudHub:\n    advertiseAddress:\n    - 127.0.0.1\n    ...\n    ...\n')),(0,a.kt)("p",null,"To apply the changed the configuration file and take it into effect, we need to restart the ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," pod. You can run ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl delete pod")," command to stop the original ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," pod, and k8s will ensure a new ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," pod is created with the new updated configuration."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'# kubectl get pod -n kubeedge\nNAME                        READY   STATUS    RESTARTS   AGE\ncloudcore-f88bbf5bb-kcvf4   1/1     Running   0          82m\n# kubectl delete pod cloudcore-f88bbf5bb-kcvf4 -nkubeedge\npod "cloudcore-f88bbf5bb-kcvf4" deleted\n')),(0,a.kt)("h4",{id:"cloudcore-in-binary-mode-1"},"cloudcore in binary mode"),(0,a.kt)("p",null,"If you deploy ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," in binary mode. The default configuration file is located on ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/kubeedge/config/cloudcore.yaml"),". You can modify it with ",(0,a.kt)("inlineCode",{parentName:"p"},"vim")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"vi")," command. If your operating system supports ",(0,a.kt)("inlineCode",{parentName:"p"},"systemd")," and manage ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," with ",(0,a.kt)("inlineCode",{parentName:"p"},"systemd"),", you can run ",(0,a.kt)("inlineCode",{parentName:"p"},"systemctl restart cloudcore")," to restart ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," with updated configuration. If not, you can just use ",(0,a.kt)("inlineCode",{parentName:"p"},"pkill")," command to stop origin ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," progress, and start it again manually."),(0,a.kt)("h3",{id:"how-to-modify-edgecore-configuration"},"How to modify edgecore configuration?"),(0,a.kt)("p",null,"We always deploy ",(0,a.kt)("inlineCode",{parentName:"p"},"edgecore")," in binary mode, that means, we couldn't deploy ",(0,a.kt)("inlineCode",{parentName:"p"},"edgecore")," in a pod. And the default configuration file is located on ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/kubeedge/config/edgecore.yaml"),". You can modify it with ",(0,a.kt)("inlineCode",{parentName:"p"},"vim")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"vi")," command. If your operating system supports ",(0,a.kt)("inlineCode",{parentName:"p"},"systemd")," and manage ",(0,a.kt)("inlineCode",{parentName:"p"},"edgecore")," with ",(0,a.kt)("inlineCode",{parentName:"p"},"systemd"),", you can run ",(0,a.kt)("inlineCode",{parentName:"p"},"systemctl restart edgecore")," to restart ",(0,a.kt)("inlineCode",{parentName:"p"},"edgecore")," with updated configuration. If not, you can just use ",(0,a.kt)("inlineCode",{parentName:"p"},"pkill")," command to stop origin ",(0,a.kt)("inlineCode",{parentName:"p"},"edgecore")," progress, and start it again manually."),(0,a.kt)("h1",{id:"frequently-asked-questions"},"Frequently Asked Questions"),(0,a.kt)("p",null,"The following description contains some common problems that might happen during the installation progress, and includes the recommended solutions to resolve it."),(0,a.kt)("h2",{id:"cloudcore-pre-flight-check-failed"},"cloudcore pre-flight check failed"),(0,a.kt)("p",null,"cloudcore error log contains the below words:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"error execution phase preflight: [preflight] Some fatal errors occurred\n")),(0,a.kt)("p",null,"This may be related to a previous installation failure having left over files from the previous installation attempt. You should run ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm reset")," command to clean up those files."),(0,a.kt)("p",null,"Other errors during the installation you can fix by following the steps shown on the screen according to the error prompt."),(0,a.kt)("h2",{id:"timed-out-waiting-for-the-condition"},"timed out waiting for the condition"),(0,a.kt)("p",null,"When you install ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," in container mode with command ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm init"),", if you encounter the below problems:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"# keadm init\nKubernetes version verification passed, KubeEdge installation will start...\nError: timed out waiting for the condition\nUsage:\n  keadm init [flags]\n\nExamples:\n\nkeadm init\n- This command will render and install the Charts for Kubeedge cloud component\n\n...\n...\n\nexecute keadm command failed:  timed out waiting for the condition\n")),(0,a.kt)("p",null,"Due to the fact that the progress of installing cloudcore components in container mode is the same as deploying any one application within a k8s cluster, we can use all the default k8s methods of debugging an application in k8s. By invoking the ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm init")," command, we'll deploy all of ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," related resources in k8s ",(0,a.kt)("inlineCode",{parentName:"p"},"kubeedge")," namespace. So you can get important information about all related resources with command ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl get all -n kubeedge")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"# kubectl get all -nkubeedge\nNAME                             READY   STATUS             RESTARTS   AGE\npod/cloudcore-644d8f55df-sj7xc   0/1     ImagePullBackOff   0          5m58s\n\nNAME                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                             AGE\nservice/cloudcore   ClusterIP   10.96.179.211   <none>        10000/TCP,10001/TCP,10002/TCP,10003/TCP,10004/TCP   5m58s\n\nNAME                        READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/cloudcore   0/1     1            0           5m58s\n\nNAME                                   DESIRED   CURRENT   READY   AGE\nreplicaset.apps/cloudcore-644d8f55df   1         1         0       5m58s\n")),(0,a.kt)("p",null,"If all the resources are created, then you can check whether ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," pod is in Running status."),(0,a.kt)("h3",{id:"cloudcore-in-pending-status"},"cloudcore in pending status"),(0,a.kt)("p",null,"If the pod ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," is in ",(0,a.kt)("inlineCode",{parentName:"p"},"Pending")," status, it's often due to pod scheduling failures. You can run ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl describe")," command to try to fix it. For example, the output may be like shown below."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"# kubectl get pod -n kubeedge\nNAME                        READY   STATUS    RESTARTS   AGE\ncloudcore-f88bbf5bb-78hzb   0/1     Pending   0          111s\n# kubectl describe pod cloudcore-f88bbf5bb-78hzb -nkubeedge\nName:             cloudcore-f88bbf5bb-78hzb\nNamespace:        kubeedge\n\n...\n...\n\nEvents:\n  Type     Reason            Age                  From               Message\n  ----     ------            ----                 ----               -------\n  Warning  FailedScheduling  55s (x3 over 2m13s)  default-scheduler  0/1 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/control-plane: }, that the pod didn't tolerate.\n")),(0,a.kt)("p",null,"We can see that the reason is that ",(0,a.kt)("inlineCode",{parentName:"p"},"0/1 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/control-plane: }, that the pod didn't tolerate.")," This is often occurs when you only have one control plane node. By default, your cluster will not schedule Pods on the control plane nodes for security reasons. If you want to be able to schedule Pods on the control plane nodes, for example in a single machine Kubernetes cluster, run:\n",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl taint nodes --all node-role.kubernetes.io/control-plane- node-role.kubernetes.io/master-"),"\nFor more details, please refer to ",(0,a.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#control-plane-node-isolation"},"k8s docs"),". And then you can find your ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," is running successfully and in ",(0,a.kt)("inlineCode",{parentName:"p"},"Running")," status."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"# kubectl get pod -n kubeedge\nNAME                        READY   STATUS    RESTARTS   AGE\ncloudcore-f88bbf5bb-78hzb   1/1     Running   0          9m1s\n")),(0,a.kt)("p",null,"For more details about taint and toleration, you can refer to ",(0,a.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/"},"k8s official docs")),(0,a.kt)("h3",{id:"cloudcore-in-imagepullbackoff-status"},"cloudcore in ImagePullBackOff status"),(0,a.kt)("p",null,"If the pod ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," is in ",(0,a.kt)("inlineCode",{parentName:"p"},"ImagePullBackOff")," status, it's often due to pod image issues. You can run ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl describe")," command to find more details. For example, the output may be showing like below."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'# kubectl describe pod cloudcore-644d8f55df-sj7xc -nkubeedge\n\n...\n...\n\nEvents:\n  Type     Reason     Age                     From               Message\n  ----     ------     ----                    ----               -------\n  Normal   Scheduled  8m39s                   default-scheduler  Successfully assigned kubeedge/cloudcore-644d8f55df-sj7xc to kind-control-plane\n  Normal   Pulling    6m59s (x4 over 8m39s)   kubelet            Pulling image "kubeedge/cloudcore:v1.12.19"\n  Warning  Failed     6m58s (x4 over 8m37s)   kubelet            Failed to pull image "kubeedge/cloudcore:v1.12.19": rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/kubeedge/cloudcore:v1.12.19": failed to resolve reference "docker.io/kubeedge/cloudcore:v1.12.19": docker.io/kubeedge/cloudcore:v1.12.19: not found\n  Warning  Failed     6m58s (x4 over 8m37s)   kubelet            Error: ErrImagePull\n  Warning  Failed     6m45s (x6 over 8m37s)   kubelet            Error: ImagePullBackOff\n  Normal   BackOff    3m36s (x20 over 8m37s)  kubelet            Back-off pulling image "kubeedge/cloudcore:v1.12.19"\n')),(0,a.kt)("p",null,"Here we can find the core reason why cloudcore did't start successfully. It's due to ",(0,a.kt)("inlineCode",{parentName:"p"},'Failed to pull image "kubeedge/cloudcore:v1.12.19": rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/kubeedge/cloudcore:v1.12.19": failed to resolve reference "docker.io/kubeedge/cloudcore:v1.12.19": docker.io/kubeedge/cloudcore:v1.12.19: not found'),". There's no ",(0,a.kt)("inlineCode",{parentName:"p"},"docker.io/kubeedge/cloudcore:v1.12.19")," image. In other words, we specified a wrong kubeedge version, which does not exist. So we can run ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm reset")," to clear the last installation, or just run ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl delete ns kubeedge")," directly, and then run ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm init")," to start a new installation, with a correct version."),(0,a.kt)("p",null,"During the cloudcore container installation progress, keadm will pull the required images from dockerhub by default. Users can pull the required images in advance, which is also supported by ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm"),". To do so, users can run ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm config images")," related commands to display or pull all the required images."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"# keadm config images pull --kubeedge-version=v1.12.0 --part=cloud\nPulling kubeedge/iptables-manager:v1.12.0 ...\nSuccessfully pulled kubeedge/iptables-manager:v1.12.0\nPulling kubeedge/controller-manager:v1.12.0 ...\nSuccessfully pulled kubeedge/controller-manager:v1.12.0\nPulling kubeedge/admission:v1.12.0 ...\nSuccessfully pulled kubeedge/admission:v1.12.0\nPulling kubeedge/cloudcore:v1.12.0 ...\nSuccessfully pulled kubeedge/cloudcore:v1.12.0\n")),(0,a.kt)("h3",{id:"cloudcore-in-crashloopbackoff-status"},"cloudcore in CrashLoopBackOff status"),(0,a.kt)("p",null,"If ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," pod is in ",(0,a.kt)("inlineCode",{parentName:"p"},"CrashLoopBackOff")," status, it means that cloudcore pod startup failed. Users should check cloudcore logs by running ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl logs")," command. And fix it according to the log error."),(0,a.kt)("h2",{id:"edgecore-failed-to-get-ca-certificate"},"EdgeCore failed to get CA certificate"),(0,a.kt)("p",null,"During the edgecore installation, edgecore will communicate with cloudcore to get the CA certificate. Users can encounter the below issues:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'failed to get CA certificate, err: Get "https://192.168.47.128:10002/ca.crt": dial tcp 192.168.47.128:10002: connect: connection refused\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'failed to get CA certificate, err: Get "https://192.168.47.128:10002/ca.crt": EOF\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'Error: failed to get CA certificate, err: Get "https://192.168.47.128:10002/ca.crt": dial tcp 192.168.47.128:10002: connect: no route to host\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'failed to get CA certificate, err: Get "https://192.168.47.128:10002/ca.crt": dial tcp 192.168.47.128:10002: i/o timeout\n')),(0,a.kt)("p",null,"Troubleshooting step:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Does the cloudcore IP address, the edge node is configured to join to, exist in the cloudcore advertise-address list?")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Can the edgecore connect to the cloudcore IP address? Are the two nodes connected over the physical network? Are there firewall restrictions?")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Do cloudcore components on the cloud side start successfully and are the accessed ports(e.g. 10000 and 10002) listening?")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"If all the above preceding steps were checked and are not showing any problems, run the following command to check whether cloudcore logs contain any errors: ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl logs cloudcore-xxxx -n kubeedge")))),(0,a.kt)("h2",{id:"keadm-join-pull-image-failed-in-edge-nodes"},(0,a.kt)("inlineCode",{parentName:"h2"},"keadm join")," pull image failed in edge nodes"),(0,a.kt)("p",null,"Users may encounter the below errors when running ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm join")," command:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"edge node join failed: pull Images failed: xxx\n")),(0,a.kt)("p",null,"Troubleshooting steps:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Can edge nodes access the Internet? ",(0,a.kt)("inlineCode",{parentName:"li"},"keadm join")," will by default pull ",(0,a.kt)("inlineCode",{parentName:"li"},"kubeedge/installation-package")," image, from dockerhub. If so, users should fix according to the specific error information."),(0,a.kt)("li",{parentName:"ul"},"If edge nodes cannot access the Internet, there're two ways to avoid this error:",(0,a.kt)("ol",{parentName:"li"},(0,a.kt)("li",{parentName:"ol"},"download images on another machines which can access the Internet, and load images manually to the edge nodes"),(0,a.kt)("li",{parentName:"ol"},"download images on another machines which can access the Internet, and push images to an internal image repository, and then run ",(0,a.kt)("inlineCode",{parentName:"li"},"keadm join")," command with flag ",(0,a.kt)("inlineCode",{parentName:"li"},"--image-repository=xxx")," to specify the internal image repository.")))),(0,a.kt)("h2",{id:"token-related-issues"},"Token related issues"),(0,a.kt)("h3",{id:"error-token-credentials-are-in-the-wrong-format"},"Error: token credentials are in the wrong format"),(0,a.kt)("p",null,"If you find that edgecore don't start, and the edgecore log contains error message like below"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"F1121 14:14:39.583329 3644556 certmanager.go:94] Error: token credentials are in the wrong format\n")),(0,a.kt)("p",null,"This means the edgecore token is not correct. You should run ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm gettoken")," on the cloud side to get token, and then copy it to ",(0,a.kt)("inlineCode",{parentName:"p"},"modules.edgeHub.token")," field."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'# cat /etc/kubeedge/config/edgecore.yaml \napiVersion: edgecore.config.kubeedge.io/v1alpha2\nkind: EdgeCore\nmodules:\n  edgeHub:\n    ...\n    ...\n    token: ""      # --- here is token, which will be used when joining edge nodes to cloud.\n\n')),(0,a.kt)("h3",{id:"invalid-token"},"Invalid Token"),(0,a.kt)("p",null,"If edgecore log contains errors like below"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"F1121 14:22:42.419103 3646881 certmanager.go:94] Error: failed to get edge certificate from the cloudcore, error: Invalid authorization token\n")),(0,a.kt)("p",null,"And cloudcore log contains errors like below"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"E1121 06:22:42.418947       1 server.go:104] failed to sign the certificate for edgenode: edge-node, invalid token\n")),(0,a.kt)("p",null,"This means that you copied an INCORRECT token to edgecore configuration. So you should run ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm gettoken")," on the cloud side to get token again, and copy it to ",(0,a.kt)("inlineCode",{parentName:"p"},"modules.edgeHub.token")," field correctly and carefully."),(0,a.kt)("h2",{id:"edgecore-failed-to-pass-the-certificate-verification"},"edgecore failed to pass the certificate verification"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'Error: failed to get edge certificate from the cloudcore, error: Get "https://192.168.47.128:10002/edge.crt": x509: certificate is valid for 192.168.47.127, not 192.168.47.128\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'Error: failed to get edge certificate from the cloudcore, error: Get "https://192.168.47.128:10002/edge.crt": x509: cannot validate certificate for 192.168.47.128 because it doesn\'t contain any IP SANs\n')),(0,a.kt)("p",null,"cloudcore requires the configuration parameter advertise-address, which can contain multiple IP addresses, separated by commas, which need to be defined in advance. It's recommended to use a load balancer or gateway address, to ensure load balancing and high availability of cloudcore. Currently, this address cannot be changed once it's configured. The value of ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore-ipport")," at edgecore must exist in the cloudcore ",(0,a.kt)("inlineCode",{parentName:"p"},"advertise-address")," list."),(0,a.kt)("h2",{id:"advertise-address-related-issues"},"Advertise-address related issues"),(0,a.kt)("p",null,"The most common problems is due to that the IP address that cloudcore expose, is NOT the same as the IP address that edgecore use to connect to."),(0,a.kt)("p",null,"cloudcore expose IP address is located like below"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"# cat cloudcore.yaml \napiVersion: cloudcore.config.kubeedge.io/v1alpha1\n...\n...\nmodules:\n  cloudHub:\n    advertiseAddress:\n    - 192.168.1.251     # ------------- this IP address is what cloudcore expose.\n...\n...\n")),(0,a.kt)("p",null,"IP address that edgecore use to connect to cloud is like below:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"# cat edgecore.yaml \napiVersion: edgecore.config.kubeedge.io/v1alpha2\nkind: EdgeCore\nmodules:\n  edgeHub:\n    enable: true\n    heartbeat: 15\n    httpServer: https://192.168.1.251:10002   # ----- this is edgecore used to get ca/certs\n    messageBurst: 60\n    messageQPS: 30\n    projectID: e632aba927ea4ac2b575ec1603d56f10\n    quic:\n      enable: false\n      handshakeTimeout: 30\n      readDeadline: 15\n      server: 192.168.1.251:10001  # ----- this is edgecore used to connect cloud\n      writeDeadline: 15\n    websocket:\n      enable: true\n      handshakeTimeout: 30\n      readDeadline: 15\n      server: 192.168.1.251:10000 # ----- this is edgecore used to connect cloud\n      writeDeadline: 15\n\n...\n...\n\n")),(0,a.kt)("p",null,"First, now KubeEdge don't support update cloudcore advertiseAddress, so it's very important for users to set one or more advertise addresses in installation progress."),(0,a.kt)("p",null,"One important thing is that the two IP address should be kept the same. Or edgecore logs will report the following errors"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"E1118 16:00:52.632311 1947817 ws.go:78] dial websocket error(x509: certificate is valid for 192.168.1.251, not 127.0.0.1), response message: \nE1118 16:00:52.632338 1947817 websocket.go:90] Init websocket connection failed x509: certificate is valid for 192.168.1.251, not 127.0.0.1\n")),(0,a.kt)("p",null,"So in one word, in our installation, we must ensure the two IP address are the same, regardless of which method we choose, ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm init")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm deprecated init")," or run cloudcore manually, ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm join")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm deprecated join")," or run edgecore manually. In other words, we must use ",(0,a.kt)("inlineCode",{parentName:"p"},"--advertise-address")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"--cloudcore-ipport")," flags in the command line."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"keadm init --advertise-address=${THE-EXPOSED-IP}\nkeadm deprecated init --advertise-address=${THE-EXPOSED-IP}\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"keadm join --cloudcore-ipport=${THE-EXPOSED-IP}:10000\nkeadm deprecated join --cloudcore-ipport=${THE-EXPOSED-IP}:10000\n")),(0,a.kt)("p",null,"By default, if we just run ",(0,a.kt)("inlineCode",{parentName:"p"},"keadm init --advertise-address=${THE-EXPOSED-IP} --profile version=v1.12.0")," to install cloudcore. We'll create a ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," service with ",(0,a.kt)("inlineCode",{parentName:"p"},"ClusterIP")," as its ServiceType. And a ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," pod which will use ",(0,a.kt)("inlineCode",{parentName:"p"},"hostNetwork"),", which means that the pod will run in the host network of the node where the pod is deployed. So here ",(0,a.kt)("inlineCode",{parentName:"p"},"${THE-EXPOSED-IP}")," should be replaced with IP address of your k8s node, where ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," is deployed. You can run ",(0,a.kt)("inlineCode",{parentName:"p"},"kubectl get node -owide")," to get k8s node IP addresses. And we also should use this IP address to join edge nodes."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"# kubectl get pod -nkubeedge -owide\nNAME                        READY   STATUS    RESTARTS   AGE     IP           NODE                 NOMINATED NODE   READINESS GATES\ncloudcore-f88bbf5bb-blgzv   1/1     Running   0          8m42s   172.18.0.2   kind-control-plane   <none>           <none>\n\n# kubectl get node -owide\nNAME                      STATUS     ROLES                  AGE   VERSION                                                    INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME\nkind-control-plane        Ready      control-plane,master   20m   v1.21.1                                                    172.18.0.2      <none>        Ubuntu 21.04         4.15.0-169-generic   containerd://1.5.2\n")),(0,a.kt)("p",null,"The above output shows that the IP address of the pod is the same as that of the k8s node, both IP addresses are ",(0,a.kt)("inlineCode",{parentName:"p"},"172.18.0.2"),". This also indicates that the pod is running in the host network of the node. So we should use ",(0,a.kt)("inlineCode",{parentName:"p"},"172.18.0.2")," as ",(0,a.kt)("inlineCode",{parentName:"p"},"${THE-EXPOSED-IP}"),", but not others. Or edgecore will report below errors:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'F1121 15:21:15.154526 3671032 certmanager.go:94] Error: failed to get CA certificate, err: Get "https://10.96.179.211:10002/ca.crt": dial tcp 10.96.179.211:10002: i/o timeout\n')),(0,a.kt)("p",null,"One more important thing about ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," container mode is about how to expose cloudcore port to edge nodes. In container mode, we will also create a cloudcore service. And it's your duty to choose a LoadBalancer or adjust it to ",(0,a.kt)("inlineCode",{parentName:"p"},"NodePort")," ServiceType, to expose ",(0,a.kt)("inlineCode",{parentName:"p"},"cloudcore")," service to edge nodes. For more details, please reference ",(0,a.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types"},"k8s service docs")),(0,a.kt)("h2",{id:"runtime\u8fd0\u884c\u65f6\u76f8\u5173\u95ee\u9898"},"Runtime(\u8fd0\u884c\u65f6)\u76f8\u5173\u95ee\u9898"),(0,a.kt)("h3",{id:"unknown-service-runtimev1alpha2imageservice"},"unknown service runtime.v1alpha2.ImageService"),(0,a.kt)("p",null,"\u5982\u679c\u4f60\u5728\u6267\u884ckeadm join\u65f6\u9047\u5230\u4e86\u7c7b\u4f3c\u5982\u4e0b\u62a5\u9519\uff1a"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"execute keadm command failed: edge node join failed: pull Images failed: rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.ImageService\n")),(0,a.kt)("p",null,"\u8bf4\u660e\u4f60\u7684containerd\u6ca1\u6709\u5f00\u542f",(0,a.kt)("inlineCode",{parentName:"p"},"cri"),"\u63d2\u4ef6\uff0c\u4f60\u53ef\u4ee5\u68c0\u67e5containerd\u7684\u914d\u7f6e\u6587\u4ef6",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/containerd/config.toml"),"\u4e2d\u7684",(0,a.kt)("inlineCode",{parentName:"p"},"disabled_plugins"),"\u5b57\u6bb5\u662f\u5426\u5305\u542b",(0,a.kt)("inlineCode",{parentName:"p"},"cri"),"\u3002\u4f60\u53ef\u4ee5\u901a\u8fc7\u7f16\u8f91\u914d\u7f6e\u6587\u4ef6\uff0c\u5220\u9664",(0,a.kt)("inlineCode",{parentName:"p"},"disabled_plugins"),"\u4e2d\u7684",(0,a.kt)("inlineCode",{parentName:"p"},"cri"),"\uff0c\u4fee\u6539\u4e4b\u540e\u8bf7\u91cd\u542fcontainerd\u3002"),(0,a.kt)("h3",{id:"failed-to-reserve-sandbox-name"},"failed to reserve sandbox name"),(0,a.kt)("p",null,"\u5982\u679c\u4f60\u5728\u6267\u884ckeadm join\u65f6\u9047\u5230\u4e86\u7c7b\u4f3c\u5982\u4e0b\u62a5\u9519\uff1a"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'execute keadm command failed: edge node join failed: copy resources failed: rpc error: code = Unknown desc = failed to reserve sandbox name "edgecore_kubeedge__0": name "edgecore_kubeedge__0" is reserved for ...\n')),(0,a.kt)("p",null,"\u8bf4\u660e\u5728\u4f60\u7684\u673a\u5668\u4e0a\u6709\u6b8b\u7559\u7684\u540c\u540dcontainerd\u5bb9\u5668\u6216\u8005\u4efb\u52a1\uff0c\u4f60\u53ef\u4ee5\u6309\u7167\u5982\u4e0b\u6b65\u9aa4\u6e05\u7406\uff1a "),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"ctr -n k8s.io t ls"),", \u5982\u679c\u6709\u6b8b\u7559\u7684task\uff0c\u8bf7\u6267\u884c",(0,a.kt)("inlineCode",{parentName:"li"},"ctr -n k8s.io t kill {task id}"),"\u6e05\u7406"),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("inlineCode",{parentName:"li"},"ctr -n k8s.io c ls"),", \u5982\u679c\u6709\u6b8b\u7559\u7684\u5bb9\u5668\uff0c\u8bf7\u6267\u884c",(0,a.kt)("inlineCode",{parentName:"li"},"ctr -n k8s.io c rm {container id}"),"\u6e05\u7406"),(0,a.kt)("li",{parentName:"ol"},"\u6267\u884c",(0,a.kt)("inlineCode",{parentName:"li"},"systemctl restart containerd.service"),"\u91cd\u542fcontainerd")),(0,a.kt)("h3",{id:"cni-plugin-not-initializedcni-config-uninitialized"},"cni plugin not initialized/cni config uninitialized"),(0,a.kt)("p",null,"\u76ee\u524d\u5728\u4f7f\u7528cri runtime\u65f6\uff0c\u6267\u884ckeadm join\u9700\u8981\u5148\u5b89\u88c5cni plugin\u5e76\u914d\u7f6ecni config\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u4ee5\u4e0b\u6b65\u9aa4\u6267\u884c\u3002"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"\u4ece ",(0,a.kt)("a",{parentName:"li",href:"https://github.com/containernetworking/plugins/releases"},"https://github.com/containernetworking/plugins/releases")," \u4e0b\u8f7d cni-plugins-{OS}-{ARCH}-{VERSION}.tgz\uff0c\u5e76\u5c06\u5176\u89e3\u538b\u5230/opt/cni/bin:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"$ mkdir -p /opt/cni/bin\n$ tar Cxzvf /opt/cni/bin cni-plugins-linux-amd64-v1.1.1.tgz\n")),(0,a.kt)("ol",{start:2},(0,a.kt)("li",{parentName:"ol"},"\u521b\u5efaCNI config")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'$ mkdir -p /etc/cni/net.d/\n\n$ cat >/etc/cni/net.d/10-containerd-net.conflist <<EOF\n{\n  "cniVersion": "1.0.0",\n  "name": "containerd-net",\n  "plugins": [\n    {\n      "type": "bridge",\n      "bridge": "cni0",\n      "isGateway": true,\n      "ipMasq": true,\n      "promiscMode": true,\n      "ipam": {\n        "type": "host-local",\n        "ranges": [\n          [{\n            "subnet": "10.88.0.0/16"\n          }],\n          [{\n            "subnet": "2001:db8:4860::/64"\n          }]\n        ],\n        "routes": [\n          { "dst": "0.0.0.0/0" },\n          { "dst": "::/0" }\n        ]\n      }\n    },\n    {\n      "type": "portmap",\n      "capabilities": {"portMappings": true}\n    }\n  ]\n}\nEOF\n')),(0,a.kt)("ol",{start:3},(0,a.kt)("li",{parentName:"ol"},"\u91cd\u542fcontainerd ")),(0,a.kt)("h3",{id:"cgroup-driver-\u4e0d\u5339\u914d"},"cgroup driver \u4e0d\u5339\u914d"),(0,a.kt)("p",null,"\u5982\u679c\u4f60\u5728\u5b89\u88c5EdgeCore\u51fa\u73b0\u5982\u4e0b\u62a5\u9519\uff1a"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'failed to create shim task: OCI runtime create failed: runc create failed: expected cgroupsPath to be of format "slice:prefix:name" for systemd cgroups\n')),(0,a.kt)("p",null,"\u6216\u8005\u5728EdgeCore\u65e5\u5fd7\u4e2d\u51fa\u73b0\uff1a"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'kubelet cgroup driver: "cgroupfs" is different from docker cgroup driver: "systemd"\n')),(0,a.kt)("p",null,"\u8bf4\u660e\u4f60\u5b89\u88c5\u7684\u8fd0\u884c\u65f6\u7684cgroup\u9a71\u52a8\u4e0eKubeEdge\u7684\u914d\u7f6e\u4e0d\u7b26\uff0cKubeEdge\u9ed8\u8ba4\u914d\u7f6e\u7684\u662f",(0,a.kt)("inlineCode",{parentName:"p"},"cgroupfs")," cgroup\u9a71\u52a8\u3002\u4f60\u53ef\u4ee5\u9009\u62e9\u4fee\u6539runtime\u7684\u914d\u7f6e\uff0c\u6216\u8005\u5728keadm join\u65f6\u8bbe\u7f6e",(0,a.kt)("inlineCode",{parentName:"p"},"--remote-runtime-endpoint=unix:///var/run/crio/crio.sock"),"\uff0c\u6216\u8005\u4fee\u6539EdgeCore\u7684\u914d\u7f6e\u6587\u4ef6(edgecore.yaml)\u4e2d\u7684\u5982\u4e0b\u5b57\u6bb5\uff1a"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"modules:\n  edged:\n    tailoredKubeletConfig:\n      cgroupDriver: systemd\n")),(0,a.kt)("admonition",{type:"tip"},(0,a.kt)("p",{parentName:"admonition"},"\u5f53\u4f60\u9700\u8981\u4f7f\u7528",(0,a.kt)("inlineCode",{parentName:"p"},"systemd")," cgroup\u9a71\u52a8\uff0c\u5e76\u4e14\u5728\u4f7f\u7528keadm join\u5b89\u88c5\u90e8\u5206\u7248\u672c(v1.12.0-1.12.4, v1.13.0-1.13.2, v1.14.0-1.14.2)\u7684EdgeCore\u65f6\uff0c\u53ef\u80fd\u4e5f\u4f1a\u51fa\u73b0",(0,a.kt)("inlineCode",{parentName:"p"},"OCI runtime create failed"),"\u7684\u62a5\u9519\uff0c\u5efa\u8bae\u4f7f\u7528\u5bf9\u5e94release\u7248\u672c\u7684\u6700\u65b0patch\u7248\u672c")))}p.isMDXComponent=!0}}]);